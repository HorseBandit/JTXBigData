{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymongo) (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: dnspython in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jerrod\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jerrod\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jerrod\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jerrod\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark\n",
    "%pip install pymongo\n",
    "%pip install dnspython\n",
    "%pip install numpy\n",
    "%pip install seaborn\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "import pymongo\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pyspark.sql.functions import collect_list, weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: findspark in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jerrod\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jerrod\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jerrod\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark findspark\n",
    "%pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Electricity Load Prediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Excel file into a pandas DataFrame\n",
    "pandas_df = pd.read_excel(\"./data/train_dataframes.xlsx\")\n",
    "# List of columns you want to keep\n",
    "columns_to_keep = [\"datetime\", \"DEMAND\", \"MA_X-4\", \"holiday\", \"dayOfWeek\", \"hourOfDay\", \"T2M_toc\"]\n",
    "\n",
    "# Drop all other columns except the ones specified in 'columns_to_keep'\n",
    "pandas_df = pandas_df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 36720 documents into the collection.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize MongoDB Connection\n",
    "client = MongoClient('mongodb+srv://JTXBigData:pJRAyKW9QnqE7B1G@jtxbigdatacluster.dzo50pn.mongodb.net/')\n",
    "db = client['JTXBigDataCluster']\n",
    "collection = db['training-flattened']\n",
    "\n",
    "# Convert the Pandas DataFrame to a list of dictionaries\n",
    "data_to_insert = pandas_df.to_dict('records')\n",
    "\n",
    "# Ingest the data into the MongoDB collection\n",
    "collection.insert_many(data_to_insert)\n",
    "\n",
    "print(f\"Inserted {len(data_to_insert)} documents into the collection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jerrod\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:479: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+-----------------+-------+---------+---------+-----------------+\n",
      "|           datetime|           DEMAND|           MA_X-4|holiday|dayOfWeek|hourOfDay|          T2M_toc|\n",
      "+-------------------+-----------------+-----------------+-------+---------+---------+-----------------+\n",
      "|2015-01-31 01:00:00|         954.2018|        938.00485|      0|        1|        1|25.30849609375002|\n",
      "|2015-01-31 02:00:00|913.8660000000001|       900.284075|      0|        1|        2|25.14144287109377|\n",
      "|2015-01-31 03:00:00|         903.3637|881.7043249999999|      0|        1|        3|25.00673828125002|\n",
      "|2015-01-31 04:00:00|         889.0806|876.4588250000002|      0|        1|        4|24.89971313476565|\n",
      "|2015-01-31 05:00:00|         910.1472|       879.190775|      0|        1|        5|24.82155761718752|\n",
      "|2015-01-31 06:00:00|         922.1737|       877.027925|      0|        1|        6|24.83019409179689|\n",
      "|2015-01-31 07:00:00|         939.9442|       920.381925|      0|        1|        7|25.79995117187502|\n",
      "|2015-01-31 08:00:00|        1077.8575|      1057.194625|      0|        1|        8|26.98031005859377|\n",
      "|2015-01-31 09:00:00|        1179.6601|       1138.17875|      0|        1|        9|28.03182373046877|\n",
      "|2015-01-31 10:00:00|        1255.1569|      1189.291375|      0|        1|       10|28.90606079101565|\n",
      "|2015-01-31 11:00:00|        1253.4414|      1202.799725|      0|        1|       11| 29.5551696777344|\n",
      "|2015-01-31 12:00:00|        1223.6116|      1176.489125|      0|        1|       12|30.03652343750002|\n",
      "|2015-01-31 13:00:00|        1160.2838|      1153.509625|      0|        1|       13|30.26552734375002|\n",
      "|2015-01-31 14:00:00|        1124.8878|      1138.098025|      0|        1|       14|30.21114501953127|\n",
      "|2015-01-31 15:00:00|        1112.4189|       1124.01035|      0|        1|       15|29.73275146484377|\n",
      "|2015-01-31 16:00:00|        1081.7406|      1061.039175|      0|        1|       16| 28.9882751464844|\n",
      "|2015-01-31 17:00:00|        1064.8583|       929.245075|      0|        1|       17|27.99349365234377|\n",
      "|2015-01-31 18:00:00|        1095.5704|      1057.654125|      0|        1|       18|27.02187500000002|\n",
      "|2015-01-31 19:00:00|        1116.6654|       1107.91455|      0|        1|       19| 26.5200134277344|\n",
      "|2015-01-31 20:00:00|         1094.677|       1072.61775|      0|        1|       20|26.24984130859377|\n",
      "+-------------------+-----------------+-----------------+-------+---------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize MongoDB Connection\n",
    "client = MongoClient('mongodb+srv://JTXBigData:pJRAyKW9QnqE7B1G@jtxbigdatacluster.dzo50pn.mongodb.net/')\n",
    "db = client['JTXBigDataCluster']\n",
    "collection = db['training-flattened']\n",
    "\n",
    "# Retrieve data from MongoDB\n",
    "mongo_data = list(collection.find())\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "pandas_df = pd.DataFrame(mongo_data)\n",
    "\n",
    "# Drop the _id column provided by MongoDB if you don't need it\n",
    "if '_id' in pandas_df.columns:\n",
    "    pandas_df.drop('_id', axis=1, inplace=True)\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"MongoDBToSparkDF\").getOrCreate()\n",
    "\n",
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "spark_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
