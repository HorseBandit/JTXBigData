{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling Mean Demand Forecasting - it calculates a rolling mean of the past 'n' hours of electricity demand to forecast future demand. It uses a rolling window approach to capture short-term demand trends.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_excel(\"./data/train_dataframes.xlsx\")\n",
    "\n",
    "# Specify the rolling window size (e.g., 4 hours)\n",
    "window_size = 4\n",
    "\n",
    "# Create a new column to store the rolling mean forecast\n",
    "train_df['Rolling_Mean_Forecast'] = train_df['DEMAND'].rolling(window=window_size).mean()\n",
    "\n",
    "# Drop rows with missing values in the forecast column\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "# You can now use train_df to evaluate the accuracy of the rolling mean forecast.\n",
    "print(train_df[['datetime', 'DEMAND', 'Rolling_Mean_Forecast']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Feature Engineering - It performs custom feature engineering by creating new features that capture interactions between existing features.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_excel(\"./data/train_dataframes.xlsx\")\n",
    "\n",
    "# Define a custom feature engineering function\n",
    "def custom_feature_engineering(df):\n",
    "    # Create a feature that represents the interaction between 'week_X-2' and 'T2M_toc'\n",
    "    df['Interaction_Feature'] = df['week_X-2'] * df['T2M_toc']\n",
    "    \n",
    "    # Create a feature that represents the day of the week multiplied by 'week_X-3'\n",
    "    df['Day_Week_X-3'] = df['dayOfWeek'] * df['week_X-3']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the custom feature engineering function to the training data\n",
    "train_df = custom_feature_engineering(train_df)\n",
    "\n",
    "# You can now use train_df, including the new features, for training and prediction.\n",
    "print(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing Demand Forecasting Algorithm:a time series forecasting method that is particularly useful for demand forecasting.assigning exponentially decreasing weights to past observations, with the most recent data points having a greater impact on the forecast.\n",
    "import numpy as np\n",
    "\n",
    "def exponential_smoothing_forecast(series, alpha):\n",
    "    forecast = [series[0]]  \n",
    "    for t in range(1, len(series)):\n",
    "        forecast.append(alpha * series[t] + (1 - alpha) * forecast[t - 1])\n",
    "    return forecast\n",
    "\n",
    "# Define the alpha parameter (smoothing factor)\n",
    "alpha = 0.2\n",
    "\n",
    "# Apply exponential smoothing to DEMAND data\n",
    "demand_series = spark_df.select(\"DEMAND\").rdd.map(lambda row: row[0]).collect()\n",
    "exponential_forecast = exponential_smoothing_forecast(demand_series, alpha)\n",
    "\n",
    "# Evaluate the forecasting performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the test data\n",
    "test_demand_series = spark_test_df.select(\"DEMAND\").rdd.map(lambda row: row[0]).collect()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_demand_series, exponential_forecast))\n",
    "print(f\"RMSE for Exponential Smoothing: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Decomposition and ARIMA Forecasting Algorithm:decomposes a time series into seasonal, trend, and remainder components.\n",
    "import numpy as np\n",
    "\n",
    "def exponential_smoothing_forecast(series, alpha):\n",
    "    forecast = [series[0]]  \n",
    "    for t in range(1, len(series)):\n",
    "        forecast.append(alpha * series[t] + (1 - alpha) * forecast[t - 1])\n",
    "    return forecast\n",
    "\n",
    "# Define the alpha parameter (smoothing factor)\n",
    "alpha = 0.2\n",
    "\n",
    "# Apply exponential smoothing to DEMAND data\n",
    "demand_series = spark_df.select(\"DEMAND\").rdd.map(lambda row: row[0]).collect()\n",
    "exponential_forecast = exponential_smoothing_forecast(demand_series, alpha)\n",
    "\n",
    "# Evaluate the forecasting performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the test data\n",
    "test_demand_series = spark_test_df.select(\"DEMAND\").rdd.map(lambda row: row[0]).collect()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_demand_series, exponential_forecast))\n",
    "print(f\"RMSE for Exponential Smoothing: {rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
